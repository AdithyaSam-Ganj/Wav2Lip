# Wav2Lip - Task 1 OpeninApp / Listed 

This is a project to lip sync audio file with video file for an interview task OpeninApp / Listed. 

## Task 
I was asked to lip sync a video file from youtube with an audio file that was provided.

## Data Files 
 The final lip synced file can be found Output_File.mp4. The input files are "Input_audio_file.mp4", for audio, and "Input_video_file.mp4" ,for video. 

## Code 
  I have used a jupyter notebook to implement the task.

#### All the dependencies and the modules are imported in the notebook.  

  I have used Wav2Lip for lip syncing the audio with the video file. More information can be found in this link "https://github.com/Rudrabha/Wav2Lip"

The .ipynb notebook contains all the code including the comments that are necessary for understanding the code. 

## Running the model 

  1. The model is implemented on Google Colab. Implementing the model is as running each code block. The colab environment has to be set to GPU before commensing the execution of cells. 
  2. There are 2 inctances when the cells ask you for input data. One is for the video file and the other is for the audio file. It is adviced to upload both the files into colab before starting implementing the code.
  3. You have to upload the Video file and the Audio file into colab. Using the upload option. Later the path to both the files should be copied and pasted when prompted by the respective cells.
  4. The oupt put of the lipsync will be presented by the final code block after execution. The file can also be downloaded in the results folder in the generated Wav2Lip folder. 
